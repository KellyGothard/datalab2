# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(dist))
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(as.matrix(dist)))
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(as.matrix(dist)))
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow((dist))
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(dist))
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(dist))
nrow(dist)
# Convert distance objects to matrices
distmat <- as.matrix(as.numeric(dist), nrow = nrow(dist.inv))
nrow(dist.inf)
nrow(dist.inv)
# Convert distance objects to matrices
distmat <- matrix(as.numeric(dist), nrow = nrow(dist.inv))
# Convert distance objects to matrices
distmat <- matrix(as.numeric(dist), nrow = nrow(dist))
# Convert distance objects to matrices
distmat <- matrix(as.numeric(dist), nrow = nrow(dist))
# Convert distance objects to matrices
distmat <- matrix(as.numeric(dist), nrow = nrow(as.matrix(dist)))
distmat = as.matrix(dist)
as.numeric(distmat)
# Convert distance objects to matrices
distmat <- as.matrix(distmat)
distmat <- matrix(as.numeric(distmat), nrow = nrow(distmat))
knitr::opts_chunk$set(echo = TRUE, warning = F)
# Load libraries and set working directory
library(tidyverse)
library(ape)
library(ade4)
setwd("C:/users/beasley/dropbox/datalab")
# Read county data
county.raw <- read.table("nyt_population.csv", sep = ",", stringsAsFactors = F,
header = T)
# Retrieve county and state names
cstr <- strsplit(county.raw$county, split = "[,]")
ststr <- strsplit(county.raw$county, split = "[,]")
# Coerce into vector that can be readded to data frame
county.raw$county <- unlist(lapply(cstr, '[[', 1))
county.raw$State <- unlist(lapply(ststr, '[[', 2))
county.raw$State <- sub(".", "", county.raw$State)
# Join county data with state abbreviations
state.abbrev <- read.table("abbr-name.csv", sep = ",", header = F, stringsAsFactors = F)
colnames(state.abbrev) <- c("abbrev", "State")
county.join <- left_join(county.raw, state.abbrev)
# Read in county geocodes and remove duplicates
county.coords <- read.table("GeocodesCounties.csv", sep = ",", stringsAsFactors = F,
header = T)
# Need to only include distinct values for county and state, not latlong
county.coords %>%
group_by(county, state) %>%
select(county, state, latitude, longitude) %>%
distinct(county, state, .keep_all = T) %>%
{. ->> crds}
# Merge geocodes with county data
county <- left_join(county.join, crds, by = c("county", "abbrev"="state"))
# Clean up the dataframe
county$rank <- as.numeric(county$rank)
county <- county[!is.na(county$rank),]
county <- county[!is.na(county$latitude),]
county <- county[!is.na(county$longitude),]
county <- county[!is.na(county$popestimate2018),]
Moran.I(county$income, dist.inv)
# First method for spatial autocorrelation: Moran's I
# Create distance matrix
dist <- dist(county[,13:14], method = 'euclidean')
dist.inv[is.infinite(dist.inv)] <- 0
dist.inv <- 1/as.matrix(dist)
dist.inv[is.infinite(dist.inv)] <- 0
Moran.I(county$income, dist.inv)
pop_space <- MMRR(X = list(distmat, popmat), Y = varmat, nperm = 1)
bits <- anti_join(county.join, county, by = "county")
qplot(bits$abbrev, geom = "bar")
non.bits <- summarise(county, num = n(county$county))
non.bits <- summarise(county$State, num = n())
non.bits <- summarise(county$State, num = count())
non.bits <- summarise(county, num = count(State))
non.bits <- table(county$State)
non.bits
bits <- table(bits$State)
bits
bits[1]
# Remove AK and HI and see what happens
county <- county[-which(county$abbrev == "AK"),]
# Read county data
county.raw <- read.table("nyt_population.csv", sep = ",", stringsAsFactors = F,
header = T)
# Retrieve county and state names
cstr <- strsplit(county.raw$county, split = "[,]")
ststr <- strsplit(county.raw$county, split = "[,]")
# Coerce into vector that can be readded to data frame
county.raw$county <- unlist(lapply(cstr, '[[', 1))
county.raw$State <- unlist(lapply(ststr, '[[', 2))
county.raw$State <- sub(".", "", county.raw$State)
# Join county data with state abbreviations
state.abbrev <- read.table("abbr-name.csv", sep = ",", header = F, stringsAsFactors = F)
colnames(state.abbrev) <- c("abbrev", "State")
county.join <- left_join(county.raw, state.abbrev)
# Read in county geocodes and remove duplicates
county.coords <- read.table("GeocodesCounties.csv", sep = ",", stringsAsFactors = F,
header = T)
# Need to only include distinct values for county and state, not latlong
county.coords %>%
group_by(county, state) %>%
select(county, state, latitude, longitude) %>%
distinct(county, state, .keep_all = T) %>%
{. ->> crds}
# Merge geocodes with county data
county <- left_join(county.join, crds, by = c("county", "abbrev"="state"))
# Clean up the dataframe
county$rank <- as.numeric(county$rank)
county <- county[!is.na(county$rank),]
county <- county[!is.na(county$latitude),]
county <- county[!is.na(county$longitude),]
county <- county[!is.na(county$popestimate2018),]
which(county$abbrev == "AK")
which(county$abbrev == "HI")
# Remove AK and HI and see what happens
county <- county[-which(county$abbrev == "HI"),]
dist2 <- dist(county[,13:14], method = 'euclidean')
dist.inv2[is.infinite(dist.inv2)] <- 0
dist.inv2 <- 1/as.matrix(dist2)
dist.inv2[is.infinite(dist.inv2)] <- 0
Moran.I(county$rank, dist2)
dist2 <- dist(county[,13:14], method = 'euclidean')
dist.inv2 <- 1/as.matrix(dist2)
Moran.I(county$rank, dist.inv2)
sum(is.na(dist.inv2))
sum(is.infinite(dist.inv2))
dist2 <- dist(county[,13:14], method = 'euclidean')
dist.inv2 <- 1/as.matrix(dist2)
dist.inv2[is.infinite(dist.inv2)] <- 0
Moran.I(county$rank, dist.inv2)
knitr::opts_chunk$set(echo = TRUE, warning = F)
# Load libraries and set working directory
library(tidyverse)
library(ape)
library(ade4)
setwd("C:/users/beasley/dropbox/datalab")
# Read county data
county.raw <- read.table("nyt_population.csv", sep = ",", stringsAsFactors = F,
header = T)
# Retrieve county and state names
cstr <- strsplit(county.raw$county, split = "[,]")
ststr <- strsplit(county.raw$county, split = "[,]")
# Coerce into vector that can be readded to data frame
county.raw$county <- unlist(lapply(cstr, '[[', 1))
county.raw$State <- unlist(lapply(ststr, '[[', 2))
county.raw$State <- sub(".", "", county.raw$State)
# Join county data with state abbreviations
state.abbrev <- read.table("abbr-name.csv", sep = ",", header = F, stringsAsFactors = F)
colnames(state.abbrev) <- c("abbrev", "State")
county.join <- left_join(county.raw, state.abbrev)
# Read in county geocodes and remove duplicates
county.coords <- read.table("GeocodesCounties.csv", sep = ",", stringsAsFactors = F,
header = T)
# Need to only include distinct values for county and state, not latlong
county.coords %>%
group_by(county, state) %>%
select(county, state, latitude, longitude) %>%
distinct(county, state, .keep_all = T) %>%
{. ->> crds}
# Merge geocodes with county data
county <- left_join(county.join, crds, by = c("county", "abbrev"="state"))
# Clean up the dataframe
county$rank <- as.numeric(county$rank)
county <- county[!is.na(county$rank),]
county <- county[!is.na(county$latitude),]
county <- county[!is.na(county$longitude),]
county <- county[!is.na(county$popestimate2018),]
# First method for spatial autocorrelation: Moran's I
# Create distance matrix
dist <- dist(county[,13:14], method = 'euclidean')
dist.inv <- 1/as.matrix(dist)
dist.inv[is.infinite(dist.inv)] <- 0
# Calculate Moran's I
Moran.I(county$rank, dist.inv)
Moran.I(county$income, dist.inv)
# Look at variation within bottom 10%: does the map capture variability?
lowest.rank <- top_n(county$rank, n = -0.1*nrow(county$rank))
# Look at variation within bottom 10%: does the map capture variability?
lowest.rank <- subset(county, county$rank < quantile(county$rank, prob = 0.1, na.rm = TRUE))
quantile(county$rank, prob = 0.1, na.rm = TRUE)
# Look at variation within bottom 10%: does the map capture variability?
lowest.rank <- subset(county, county$rank > quantile(county$rank, prob = 0.9, na.rm = TRUE))
quantile(county$rank, prob = 0.9, na.rm = TRUE)
county$rank > quantile(county$rank, prob = 0.9, na.rm = TRUE)
# Look at variation within bottom 10%: does the map capture variability?
lowest.rank <- subset(county, which(county$rank > quantile(county$rank, prob = 0.9, na.rm = TRUE)))
# Look at variation within bottom 10%: does the map capture variability?
lowest.rank <- subset(county, rank > quantile(rank, prob = 0.9, na.rm = TRUE))
lowest.income <- subset(county, income < quantile(income, prob = 0.1, na.rm = T))
hist(lowest.income)
hist(lowest.income$income)
hist(lowest.rank$rank)
hist(lowest.rank$income)
hist(lowest.rank$rank)
hist(lowest.rank$rank)
hist(lowest.rank$income)
hist(county$income)
ggplot(data = county, aes (x = rank))+
geom_density()
ggplot(data = county, aes (x = rank))+
geom_density()
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density()
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density()
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density()+
theme_classic(base_size = 20)
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density()+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density(size = 2)+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Look at variation within rank classes vs. income classes
ggplot(data = county, aes (x = rank))+
geom_density(size = 1.5)+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Look at variation within rank classes vs. income classes
rank.quantiles <- quantile(county$rank, c(0.1, 0.9))
ggplot(data = county, aes (x = rank))+
geom_density(fill = rank.quantiles)+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Look at variation within rank classes vs. income classes
rank.density <- density(county$rank)
rank.frame <- data.frame(x = rank.density$x, y = rank.density$y)
rank.quantiles <- quantile(county$rank, c(0.1, 0.9))
rank.frame$quant <- factor(findInterval(rank.frame$x, rank.quantiles))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_discrete(breaks = quantiles, values = c("blue", "white", "red"))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = quantiles, values = c("blue", "white", "red"))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles, values = c("blue", "white", "red"))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles, values = c("deepskyblue", "white", "darkorange2"))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles, values = c("deepskyblue4", "white", "darkorange2"))
ggplot(data = rank.frame, aes (x, y))+
geom_line()+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles,
values = c("deepskyblue4", "white", "darkorange2"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
ggplot(data = rank.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles,
values = c("deepskyblue4", "white", "darkorange2"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
ggplot(data = income.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = income.frame$quantiles,
values = c("darkorange2", "white", "deepskyblue4"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
income.frame <- data.frame(x = income.density$x, y = income.density$y)
income.density <- density(county$income)
income.frame <- data.frame(x = income.density$x, y = income.density$y)
income.quantiles <- quantile(county$income, c(0.1, 0.9))
income.frame$quant <- factor(findInterval(income.frame$x, income.quantiles))
ggplot(data = income.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = income.frame$quantiles,
values = c("darkorange2", "white", "deepskyblue4"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
knitr::opts_chunk$set(echo = TRUE, warning = F)
# Load libraries and set working directory
library(tidyverse)
library(ape)
library(ade4)
setwd("")
# Look at variation within rank classes vs. income classes
rank.density <- density(county$rank)
rank.frame <- data.frame(x = rank.density$x, y = rank.density$y)
rank.quantiles <- quantile(county$rank, c(0.1, 0.9))
rank.frame$quant <- factor(findInterval(rank.frame$x, rank.quantiles))
ggplot(data = rank.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles,
values = c("deepskyblue4", "white", "darkorange2"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Do the same thing for income
income.density <- density(county$income)
income.density <- density(county$income)
income.frame <- data.frame(x = income.density$x, y = income.density$y)
income.quantiles <- quantile(county$income, c(0.1, 0.9))
income.frame$quant <- factor(findInterval(income.frame$x, income.quantiles))
ggplot(data = income.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = income.frame$quantiles,
values = c("darkorange2", "white", "deepskyblue4"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Look at variation within rank classes vs. income classes
rank.density <- density(county$rank)
rank.frame <- data.frame(x = rank.density$x, y = rank.density$y)
rank.quantiles <- quantile(county$rank, c(0.1, 0.9))
rank.frame$quant <- factor(findInterval(rank.frame$x, rank.quantiles))
ggplot(data = rank.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles,
values = c("deepskyblue4", "white", "darkorange2"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
# Do the same thing for income
income.density <- density(county$income)
income.density <- density(county$income)
income.frame <- data.frame(x = income.density$x, y = income.density$y)
income.quantiles <- quantile(county$income, c(0.1, 0.9))
income.frame$quant <- factor(findInterval(income.frame$x, income.quantiles))
ggplot(data = income.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = income.frame$quantiles,
values = c("darkorange2", "white", "deepskyblue4"))+
labs(x = "Income", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
ggplot(data = rank.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = rank.frame$quantiles,
values = c("deepskyblue4", "white", "darkorange2"))+
labs(x = "Rank", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
ggplot(data = income.frame, aes (x, y))+
geom_line(size = 2)+
geom_ribbon(aes(ymin=0, ymax=y, fill=quant))+
scale_fill_manual(breaks = income.frame$quantiles,
values = c("darkorange2", "white", "deepskyblue4"))+
labs(x = "Income", y = "Density")+
theme_classic(base_size = 20)+
theme(axis.text.y = element_blank())
citation("MASS")
setwd("c:/users/beasley/documents/datalab2")
quant.trigger <- read.table('trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
quant.trigger <- read.table('~/smac/trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
quant.trigger <- read.table('smac/trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
install.packages('phonics')
# Load packages and set directory
library(phonics)
?phonics
# Load packages and set directory
library(phonics)
setwd("c:/users/beasley/documents/datalab2")
# Load quantitative data
quant.trigger <- read.table('smac/trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
# Test the phonics function
phonics(quant.trigger$District, method = "soundex")
# Test the phonics function
head(phonics(quant.trigger$District, method = "soundex", clean = T))
# Seems to be working? Count how many we have; does it match known districts?
district.soundex <- phonics(quant.trigger$District, method = "soundex", clean = T)
unique(district.soundex)
# Test the phonics function
head(phonics(quant.trigger$District, method = "soundex.refined", clean = T))
# Seems to be working? Count how many we have; does it match known districts?
district.soundex <- phonics(quant.trigger$District, method = "soundex", clean = T)
unique(district.soundex)
# Seems to be working? Count how many we have; does it match known districts?
district.soundex <- phonics(quant.trigger$District, method = "soundex.refined",
clean = T)
unique(district.soundex)
length(unique(quant.trigger$District))
length(unique(district.soundex))
length(unique(district.soundex$soundex.refined))
length(unique(district.soundex$word))
length(unique(quant.trigger$District))
unique(district.soundex)
unique(quant.trigger$District)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
select(District, Chiefdom) %>%
mutate.if(is.character, str_squish)
library(tidyverse)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
select(District, Chiefdom) %>%
mutate.if(is.character, str_squish)
??mutate.if
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
select(District, Chiefdom) %>%
mutate_if(is.character, str_squish)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
select(District, Chiefdom) %>%
mutate_if(is.character, str_squish) %>%
{. ->> qt.nospace}
head(qt.nospace$Chiefdom)
str_squish("hi there")
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
mutate_if(is.character, str_squish(District, Chiefdom)) %>%
{. ->> qt.nospace}
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
mutate_if(is.character, str_squish(c(District, Chiefdom))) %>%
{. ->> qt.nospace}
str_squish("hi there")
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
select(District, Chiefdom) %>%
mutate_if(is.character, gsub(" ", "", fixed = T)) %>%
{. ->> qt.nospace}
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
mutate_if(is.character, gsub(c(District, Chiefdom), " ", "", fixed = T)) %>%
{. ->> qt.nospace}
# Remove spaces from district and chiefdom names --------------------------
quant.trigger %>%
gsub(c(District, Chiefdom), " ", "", fixed = T) %>%
{. ->> qt.nospace}
# Remove spaces from district and chiefdom names --------------------------
quant.trigger$District:Chiefdom <- gsub(quant.trigger$District:Chiefdom, " ", "",
fixed = T)
quant.trigger$District:Chiefdom
# Remove spaces from district and chiefdom names --------------------------
quant.trigger[,c("Disrict", "Chiefdom")] <-
gsub(quant.trigger[,c("District", "Chiefdom")], " ", "", fixed = T)
# Load quantitative data
quant.trigger <- read.table('smac/trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
# Remove spaces from district and chiefdom names --------------------------
quant.nospace <- gsub(quant.trigger[,c("District", "Chiefdom")], " ", "", fixed = T)
gsub("hi there", " ", "", fixed = T)
gsub("\\s", "", "hi there")
# Remove spaces from district and chiefdom names --------------------------
quant.nospace <- gsub("\\s", "", quant.trigger[,c("District", "Chiefdom")])
head(quant.nospace)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger$Chiefdom <- gsub("\\s", "", quant.trigger$Chiefdom)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger$District <- gsub(quant.trigger$District)
quant.trigger$Chiefdom <- gsub("\\s", "", quant.trigger$Chiefdom)
# Load quantitative data
quant.trigger <- read.table('smac/trigger_na.csv', sep = ',', header = T,
stringsAsFactors = F)
# Remove spaces from district and chiefdom names --------------------------
quant.trigger$District <- gsub("\\s", "", quant.trigger$District)
quant.trigger$Chiefdom <- gsub("\\s", "", quant.trigger$Chiefdom)
# Soundex, revisited --------------------------------
qt.soundex <- phonics(quant.trigger[,c("District", "Chiefdom")],
method = "soundex.refined", clean = T)
# Soundex, revisited --------------------------------
dist.soundex <- phonics(quant.trigger$District, method = "soundex.refined", clean = T)
unique(dist.soundex)
chief.soundex <- phonics(quant.trigger$Chiefdom, method = "soundex.refined", clean = T)
unique(chief.soundex)
length(unique(chief.soundex))
length(unique(chief.soundex$word))
qt.soundex <- cbind(dist.soundex, chief.soundex)
colnames(qt.soundex)
colnames(qt.soundex) <- c("dist.word", "dist.soundex", "chief.word", "chief.soundex")
unique(quant.trigger$Chiefdom)
length(unique(quant.trigger$Chiefdom))
